<h3><a href="https://analytics.ncsu.edu/">Institute for Advanced Analytics</a></h3>
NC State University
<br>
<h3><b>Distributed Data Processing Module</b></h3>
<br>
<br><b>Session 1 - Open Source Ecosystem for Distributed Computing</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Overview of an Open Source Platform for Distributed Processing
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Tools & Services - Spark, Hadoop, Zeppelin, Ambari, Kafka, NiFi, Ranger, Hive, HBase, plus many others
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Platform Administration - Security, governance, operations, scalability, and deployment considerations
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Distributed architectures & use cases
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Demo - Deploying a distribute, Hadoop cluster (Pure Open Source)
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Demo - Deploying a distribute, Hadoop cluster (Cloud Deployment)
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Hands-on Lab: Clone repo and install Docker containers
<br>
<br><b>Session 2 - Apache Hive - Distributed SQL</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Create Hive (SQL on Hadoop) Tables
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Tools to access / process data in Hive
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;NoSQL distributed data processing
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Hands-on Lab: Create a Hive table, query a hive table, use SparkSQL, query HBase (a NoSQL database).
<br>
<br><b>Session 3 - Spark Machine Learning</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Building and deploying a Spark machine learning model
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Considerations for ML in distributed environments
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Python and R for distributed compute
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Config and tuning
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Hands-on Lab: Build a Spark machine learning model using publicly available datasets
<br>
<br><b>Session 4 - Real-time Data Ingestion and load data into Hadoop</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Understanding real-time open source services
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Building a real-time data ingest pipeline using Apache NiFi
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Working with Apache Kafka
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Hands-on Lab: Ingest real-time data from an online API and land into Hadoop<br>
<br>
<br><b>Session 5 - Deploying in the Cloud</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Overview of the cloud ecosystem
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Tools and services
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;ML in the cloud
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Methods for deploying to the cloud
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Hands-on Lab: Deploy a cloud instance, load data, and execute queries / data processing jobs against cloud storage.
<br>
<br><b>Session 6 - Project</b>
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Dataset and more details will be specified at a later date.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Ingest data into Hive and execute queries to answer specificied questions.
<br>&nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;Use Spark to analyze that same data and build a basic ML model.
<br>
<br><b>References</b>
<br>
